---
title: 업그레이드 된 구글의 음성합성 모델 - Tacotron2
author: HW
date: 2020-10-03 17:00:00 +0800
categories: [Speech Synthesis]
tags: [Training]
math: true
image: /assets/img/sample/
---



# **들어가면서**



<center>(출처: https://www.pinterest.com.au/pin/332210910020186329)</center>


Tacotron1이 오픈소스로 공개되면서 많은 사람들이 이를 활용한 서비스를 많이 개발했다. <br/>

충분히 좋은 성능으로 자연스러웠지만, 구글은 더 완벽한 성능을 위한 개발을 끊임없이 진행했다.<br/><br/>

2018년 구글은 변경된 구조의 Tacotron과 Vocoder를 Griffin-Lim 대신 Wavenet을 적용한 모델을 발표했다.<br/><br/><br/>



# Introduction

딥러닝 기술 탄생 이전의 음성합성 기술엔 아쉬움이 많았다.

이미 저장된 파형의 자잘한 단위를 연결하는 방식이었기에 이질감이 상당했다.<br/>

<br/>

Vocoder의 등장과 함께 통계를 활용하여 음성이 급격하게 부드러워지기 시작했다.<br/>

그러면서 음성합성에 있던 대부분의 문제가 해결되었다. <br/><br/>



당시, 가장 유명한 vocoder는 wavenet으로 실제 인간의 음성과 비슷한 수준으로 생성할 수 있다.

성능이 좋지만 generate에 많은 시간이 소요된다는 점이 단점인데 이는 wavenet 게시글에서 자세히 알 수 있다.<br/><br/><br/>



# Tacotron2 



(Mel 생성 그림)

Tacotron2는 2가지 Task를 가지고 있다.<br/>

첫 번째는 텍스트를 input으로 받아, Mel-spectrogram을 생성하는 것 (Tacotron2 메인)

두 번째는 Mel-sepctrogram으로 음성을 생성하는 것 (wavenet 등 vocoder)

이다.<br/><br/><br/>



# Tacotron2 구조

![tacotron_model](/assets/img/insert/tacotron/tacotron_model.jpg)

(타코트론 전체 모델 그림=)

위에서 언급했듯이, Tacotron2의 Input은 char이며, output은 mel-spectrogram이다.<br/>

진행 순서는 크게 Preprocessing → Encoder → Attention → Decoder 라고 보면 된다.<br/>



요약하면 각 기능은 다음과 같다.<br/>

Encoder : input의 char를 일련의 길이의 히든 벡터(feature)로 변환<br/>

Attention : Encoder에서 생성된 히든 벡터를 시간 순서에 따라 정보를 추출하여 decoder에 전달<br/>

Decoder : Attention에서 얻은 정보를 이용해 mel-spectrogram을 생성<br/>

<br/>

자세한 내용은 다음 카테고리에서 자세히 다루겠다.<br/><br/><br/>



# Preprocessing 

(데이터셋 관련 그림)

모델 학습을 위해 input과 output이 하나로 묶인 데이터 필요하다. (텍스트와 음성)<br/><br/>

Input의 경우, 텍스트는 char 형식으로 변경하고, 음성은 mel-spectrogram으로 변환한다.<br/>
하나하나 알파벳(자음, 모음)으로 나누고 one-hot 인코딩을 통해,
 ‘안녕 반가워’ 같은 char 시퀀스를 정수열로 변경하고 모델의 input으로 사용한다.

(안녕 반가워에 대한 그림)

<br/><br/>

한글 : 초성(19개), 중성(21개), 종성(27개)<br/><br/>

Output의 경우, 음성 데이터를 spectrogram을 만들기 위해 Fourier transform 사용한다.

<br/>시간에 따른 변화를 반영할 수 없어 **특정 길이로 자르는 STFT로 spectrogram 생성**한다. <br/>

(STFT 관련 사진)

이후 spectrogram을 mel-filter bank 비선형 함수를 적용해 **low frequency 영역 확대**한다.

→ 사람 귀는 고주파보다 저주파에 민감하고, 고주파 영역이 작기 때문에 더 사람 친화적이다.
 이후 log scaling을 통해 mel-spectrogram 생성 후 label로 활용하게 된다.



(STFT: Short-Term Fourier transform)

# Encoder 

  



<br>

<br>



# Decoder

<br>



# Attention



<br><br>



# Wavnet

<br><br>



 
