---
title: 딥러닝 기반의 음성합성 모델 Tacotron
author: HW
date: 2020-09-15 17:00:00 +0800
categories: [Speech Synthesis]
tags: [Tacotron]
math: true
image: /assets/img/sample/tacotron_model.jpg

---



# **들어가면서**

![exTTS](/assets/img/insert/tacotron/taco.jpg)

어느 순간 갑자기 기계 목소리가 자연스러워졌음을 한 번쯤은 느낀 적 있을 것이다. <br/>

내 경우엔 느긋한 구글 Assistant의 목소리 때문에 그랬는지 잘 체감을 못했는데,

어쨌든 갑자기 부드럽게 음성을 제작할 수 있게 된 것엔 다 이유가 있었다. <br/>

그 대표적인 예로 이 타코트론이 전 세계의 모든 음성 합성 기술이 대폭 발전하는 데에 많은 기여를 했다.

드디어 신경망을 음성을 합치는데 까지 도달한 것이다.

그래서 구글에서 발표한 이 대단한 모델에 대해 설명하고자 한다.<br/><br/>





# Tacotron의 역할

Tacotron은 제목에서 언급했듯이 음성을 합성하기 위해 고안된 모델이다.<br/>

<br>

사이에 뭔가 넣을 예정

<br/>![exTTS](/assets/img/insert/tacotron/translateHI.png)

우리는 위와 같이 번역기를 사용하는데, 대부분의 번역은 이전의 Text에서 이후의 Text로 변환하는 Sequence to Sequence 모델을 기반으로 한다.<br>

음성 합성의 경우에 이 Seq2Seq 모델을 사용하는데,  그 구조는 다음과 같다.

![exTTS](/assets/img/insert/tacotron/seq2seq.png)

영어 Text를 input으로 넣으면, 이 Text가 vector화 되어 저장되고, 이를 바탕으로 Decoder에서 목표 Text에 대한 처리를 거친 후 프랑스어로 번역되어 output이 나온다.<br><br>

마찬가지로 Tacotron에서도 이 Seq2Seq을 활용하는데, 자세한 내용은 뒤에서 다루고자 한다. <br/><br/><br/>



# Tacotron 구조

![exTTS](/assets/img/insert/tacotron/tacotron_model.jpg)

대표 사진으로 걸어둔 사진이 Tacotron의 전체 구조이다.<br>

크게 왼쪽 아래 Character Embeddings 부터 Encoding이 이뤄지고, Attention을 거쳐서 Decoder에서 Mel-Spectrogram을 생성하는 것을 확인할 수 있다. <br>

그리고 마지막으로 CBHG를 한 번 더  거쳐서 Linear-Spectrogram을 만들고 Vocoder에게 이를 넘긴다.

그러면 하나의 완벽한 음성 합성이 완성 된다.

<br/><br/>



# Encoder

인코더는 전처리한 Text Embedding을 Pre-net과 CBHG를 거쳐 Sequences를 얻는 과정을 거친다.

(사진넣기)

순서는 Text Input -> Pre-net -> CBHG -> Output(Vector)이며, 

Pre-Net의 경우 **FC(Dense) – ReLU – Dropout – FC – ReLU – Dropout** 의 단계가 있으며,

CBHG의 경우  **Conv1D bank – Max pooling – Conv1D projections – Highway net – GRU(Bidirectional RNN)** 의 단계로 이루어져 있다. 

각 과정에 대해서는 구글링하여 알 수 있으며, 추후에 블로그에 포스팅하고자 한다.  <br>  

### ***CBHG***

![exTTS](/assets/img/insert/tacotron/CBHG_summary.png)

CBHG를 사용하는 이유는 highway를 사용함으로써 character 단위를 표현하는데 더 효율적으로 되기 때문이다.<br>

최종적으로 highway 4번에 걸쳐 나온 Vector가 Attention에 사용될 query가 된다.

![exTTS](/assets/img/insert/CBHG_detail.png)

<br>

<br>



# Decoder

Decoder에서는 Text에 대한 Vector가 여러 순환 신경망(Attention RNN, Decoder RNN)을 거쳐 Mel spectrogram을 얻는 과정을 한다.<br>

과정은 <GO> frame-> Pre-net -> Attention RNN -> Decoder RNN -> Mel spectrogram 이다.

![exTTS](/assets/img/insert/tacotron/decoder.png)

정리하자면, 가장 처음 비어있는 <GO> frame에서 시작하여 Attention의 영향을 받은 Decoder RNN을 거쳐서 Mel-Spectrogram 3개를 생성하여 출력하고, 이를 다음 과정의 Node로 사용하게 된다.<br>

지속적으로 반복하여 얻은 Mel-Sepctrogram을 활용하게 된다., 



# Attention





# Vocoder(Griffin-Lim)

