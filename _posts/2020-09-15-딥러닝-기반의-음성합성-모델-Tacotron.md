---
title: 딥러닝 기반의 음성합성 모델 Tacotron
author: HW
date: 2020-09-18 17:00:00 +0800
categories: [Speech Synthesis]
tags: [Tacotron]
math: true
image: /assets/img/sample/tacotron_model.jpg

---



# **들어가면서**

![exTTS](/assets/img/sample/taco.jpg)

어느 순간 갑자기 기계 목소리가 자연스러워졌음을 한 번쯤은 느낀 적 있을 것이다. <br/>

내 경우엔 느긋한 구글 Assistant의 목소리 때문에 그랬는지 잘 체감을 못했는데,

어쨌든 갑자기 부드럽게 음성을 제작할 수 있게 된 것엔 다 이유가 있었다. <br/>

그 대표적인 예로 이 타코트론이 전 세계의 모든 음성 합성 기술이 대폭 발전하는 데에 많은 기여를 했다.

드디어 신경망을 음성을 합치는데 까지 도달한 것이다.

그래서 구글에서 발표한 이 어마어마한 모델에 대해 설명하고자 한다.<br/><br/>





## Tacotron의 역할

Tacotron은 제목에서 언급했듯이 음성을 합성하기 위해 고안된 모델이다.<br/>

<br>

사이에 뭔가 넣을 예정

<br/>![exTTS](/assets/img/sample/translateHI.jpg)

우리는 위와 같이 번역기를 사용하는데, 대부분의 번역은 이전의 Text에서 이후의 Text로 변환하는 Sequence to Sequence 모델을 기반으로 한다.<br>

음성 합성의 경우에 이 Seq2Seq 모델을 사용하는데,  그 구조는 다음과 같다.

![exTTS](/assets/img/sample/seq2seq.jpg)

영어 Text를 input으로 넣으면, 이 Text가 vector화 되어 저장되고, 이를 바탕으로 Decoder에서 목표 Text에 대한 처리를 거친 후 프랑스어로 번역되어 output이 나온다.<br><br>

마찬가지로 Tacotron에서도 이 Seq2Seq을 활용하는데, 자세한 내용은 뒤에서 다루고자 한다. <br/><br/><br/>



## Tacotron 구조

![exTTS](/assets/img/sample/tacotron_model.jpg)

대표 사진으로 걸어둔 사진이 Tacotron의 전체 구조이다.<br>

보면 

<br/><br/>



## Encoder

MD를 처음 써보는 입장에서 연습할 겸 간단히 Intro를 작성해 보았다.<br/><br/>



갑자기 첫 글 올라가는 것보다 뻘글 하나 올리면 나중에 게을러졌을 때 조금 동기부여가 되지 않을까

앞으로 지속적으로 할 수 있도록 기도 한 번 하고 이쯤에서 글을 마무리 해야겠다. 





## Decoder





## Attention





## Vocoder(Griffin-Lim)

